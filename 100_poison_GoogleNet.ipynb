{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Copy of GoogleNet.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "seF3Lq-Tx_qM",
        "colab_type": "code",
        "outputId": "1151d97e-46a2-4d9e-fdae-8ccd83bb1eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import json\n",
        "import time\n",
        "\n",
        "import joblib\n",
        "import keras\n",
        "import tensorflow\n",
        "from keras.engine.saving import load_model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.layers import Input, GlobalAveragePooling2D, concatenate, AveragePooling2D\n",
        "from keras import models\n",
        "from keras.models import Model\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "import matplotlib.pyplot as plt\n",
        "#from keras.callbacks import tensorboard_v1\n",
        "import cv2    \n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZDPsapuyGiG",
        "colab_type": "code",
        "outputId": "eac32af9-d663-4b33-8b4c-bc9355f81afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay5D3stLyVdx",
        "colab_type": "code",
        "outputId": "8ceed5db-fd0d-4e0d-ecb1-82a2e95a5b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Final_Work_RE"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Final_Work_RE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dADCtZQT4dsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "data_dir = './poison_flowers_TRAIN/'\n",
        "train_dir = os.path.join(data_dir)\n",
        "\n",
        "data_dir1 = './flowers_TEST/'\n",
        "test_dir = os.path.join(data_dir1)\n",
        "#print(os.listdir('../train'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6gwflKg4io3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=[]\n",
        "Z=[]\n",
        "IMG_SIZE=150\n",
        "#FLOWER_DAISY_DIR='../daisy'\n",
        "FLOWER_DAISY_DIR = os.path.join('./poison_flowers_TRAIN/daisy')\n",
        "#FLOWER_SUNFLOWER_DIR='../input/flowers/flowers/sunflower'\n",
        "#FLOWER_TULIP_DIR='../input/flowers/flowers/tulip'\n",
        "#FLOWER_DANDI_DIR='../input/flowers/flowers/dandelion'\n",
        "#FLOWER_ROSE_DIR='../rose'\n",
        "FLOWER_ROSE_DIR=os.path.join('./poison_flowers_TRAIN/rose')\n",
        "FLOWER_SUNFLOWER_DIR=os.path.join('./poison_flowers_TRAIN/sunflower')\n",
        "FLOWER_TULIP_DIR=os.path.join('./poison_flowers_TRAIN/tulip')\n",
        "FLOWER_DANDI_DIR=os.path.join('./poison_flowers_TRAIN/dandelion')\n",
        "\n",
        "\n",
        "\n",
        "X1=[]\n",
        "Z1=[]\n",
        "IMG_SIZE=150\n",
        "#FLOWER_DAISY_DIR='../daisy'\n",
        "FLOWER_DAISYTest_DIR = os.path.join('./flowers_TEST/daisy')\n",
        "#FLOWER_SUNFLOWER_DIR='../input/flowers/flowers/sunflower'\n",
        "#FLOWER_TULIP_DIR='../input/flowers/flowers/tulip'\n",
        "#FLOWER_DANDI_DIR='../input/flowers/flowers/dandelion'\n",
        "#FLOWER_ROSE_DIR='../rose'\n",
        "FLOWER_ROSETest_DIR=os.path.join('./flowers_TEST/rose')\n",
        "FLOWER_SUNFLOWERTest_DIR=os.path.join('./flowers_TEST/sunflower')\n",
        "FLOWER_TULIPTest_DIR=os.path.join('./flowers_TEST/tulip')\n",
        "FLOWER_DANDITest_DIR=os.path.join('./flowers_TEST/dandelion')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gawstkl4oOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def assign_label(img,flower_type):\n",
        "    return flower_type"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnbaVIKa4tsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_train_data(flower_type,DIR):\n",
        "    for img in tqdm(os.listdir(DIR)):\n",
        "        label=assign_label(img,flower_type)\n",
        "        path = os.path.join(DIR,img)\n",
        "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
        "        \n",
        "        X.append(np.array(img))\n",
        "        Z.append(str(label))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsUzhziV6B2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_test_data(flower_type,DIR):\n",
        "    for img in tqdm(os.listdir(DIR)):\n",
        "        label=assign_label(img,flower_type)\n",
        "        path = os.path.join(DIR,img)\n",
        "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
        "        \n",
        "        X1.append(np.array(img))\n",
        "        Z1.append(str(label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUcLAtXw4w-t",
        "colab_type": "code",
        "outputId": "cc8791f5-a879-42a1-d054-026794ecbfe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "make_train_data('Daisy', FLOWER_DAISY_DIR)\n",
        "print(len(X))\n",
        "\n",
        "make_test_data('Daisy', FLOWER_DAISYTest_DIR)\n",
        "print(len(X1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 700/700 [06:00<00:00,  1.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 84/84 [00:45<00:00,  1.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "84\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nphEe8cJ6jO4",
        "colab_type": "code",
        "outputId": "f1a3b958-a87c-4e51-ff1e-b30cd63d71b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "make_train_data('Sunflower',FLOWER_SUNFLOWER_DIR)\n",
        "print(len(X))\n",
        "make_test_data('Sunflower', FLOWER_SUNFLOWERTest_DIR)\n",
        "print(len(X1))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 700/700 [06:16<00:00,  1.86it/s]\n",
            "  0%|          | 0/84 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 84/84 [00:42<00:00,  1.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cWhLxyj5N9F",
        "colab_type": "code",
        "outputId": "ea9dbd1c-5d23-41be-be90-1f8f221fefde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "make_train_data('Tulip',FLOWER_TULIP_DIR)\n",
        "print(len(X))\n",
        "make_test_data('Tulip', FLOWER_TULIPTest_DIR)\n",
        "print(len(X1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 700/700 [06:30<00:00,  1.79it/s]\n",
            "  0%|          | 0/84 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 84/84 [00:43<00:00,  1.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7pzRcA95OgB",
        "colab_type": "code",
        "outputId": "85bd7fec-3d00-4c08-aac3-b39f51b77d2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "make_train_data('Dandelion',FLOWER_DANDI_DIR)\n",
        "print(len(X))\n",
        "make_test_data('Dandelion', FLOWER_DANDITest_DIR)\n",
        "print(len(X1))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 700/700 [06:05<00:00,  1.92it/s]\n",
            "  0%|          | 0/84 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 84/84 [00:42<00:00,  1.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "336\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BlLs0R66nE1",
        "colab_type": "code",
        "outputId": "805736b3-4852-4be4-aae3-82af9fdcc5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "make_train_data('Rose',FLOWER_ROSE_DIR)\n",
        "print(len(X))\n",
        "\n",
        "make_test_data('Rose',FLOWER_ROSETest_DIR)\n",
        "print(len(X1))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 700/700 [06:04<00:00,  1.92it/s]\n",
            "  0%|          | 0/84 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 84/84 [00:43<00:00,  1.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "420\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbaqXcu940Ms",
        "colab_type": "code",
        "outputId": "db6f187a-b5c8-4de0-9fa1-9ad81d76d158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "le=LabelEncoder()\n",
        "Y=le.fit_transform(Z)\n",
        "Y=to_categorical(Y,5)\n",
        "X=np.array(X)\n",
        "X=X/255\n",
        "\n",
        "le1=LabelEncoder()\n",
        "Y1=le1.fit_transform(Z1)\n",
        "Y1=to_categorical(Y1,5)\n",
        "X1=np.array(X1)\n",
        "X1=X1/255\n",
        "\n",
        "print(X1.shape)\n",
        "print(X.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420, 150, 150, 3)\n",
            "(3500, 150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9Zkuq546wzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = X\n",
        "y_train = Y\n",
        "x_test = X1\n",
        "y_test = Y1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbRc5xFH-Ht9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRi5-nso7FuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O93bTZuGynSv",
        "colab_type": "code",
        "outputId": "4aa27487-79eb-4c38-d649-cbf1dd492bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''import os\n",
        "#train_root='../input/indoor-scenes-cvpr-2019/indoorCVPR_09/Images'#\n",
        "train_dir = './train/'\n",
        "train_root=os.path.join(train_dir)\n",
        "#vaildation_root='/home/faith/keras/dataset/vaildationdata/'\n",
        "test_dir = './test/'\n",
        "test_root=os.path.join(test_dir)\n",
        "print(train_root)'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"import os\\n#train_root='../input/indoor-scenes-cvpr-2019/indoorCVPR_09/Images'#\\ntrain_dir = './train/'\\ntrain_root=os.path.join(train_dir)\\n#vaildation_root='/home/faith/keras/dataset/vaildationdata/'\\ntest_dir = './test/'\\ntest_root=os.path.join(test_dir)\\nprint(train_root)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_AfDGAkysRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''LEARNING_RATE=0.01\n",
        "MOMENTUM=0.9\n",
        "ALPHA=0.0001\n",
        "BETA=0.75\n",
        "GAMMA=0.1\n",
        "DROPOUT=0.4\n",
        "WEIGHT_DECAY=0.0005\n",
        "LRN2D_NORM=True\n",
        "DATA_FORMAT='channels_last' # Theano:'channels_first' Tensorflow:'channels_last'\n",
        "USE_BN=True\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "IM_WIDTH=299\n",
        "IM_HEIGHT=299\n",
        "#EPOCH=200\n",
        "#batch_size=32\n",
        "NB_CLASS=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCVg5kKvy1vz",
        "colab_type": "code",
        "outputId": "d9465727-43fa-4cd4-e551-33927413d8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "'''datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.3,\n",
        "    rescale=1./255\n",
        ")\n",
        "train_generator = datagen.flow_from_directory(\n",
        "  train_root,\n",
        "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
        "  batch_size=batch_size,\n",
        "  class_mode='categorical', subset='training'\n",
        ")'''"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"datagen = ImageDataGenerator(\\n    rotation_range=30,\\n    width_shift_range=0.2,\\n    height_shift_range=0.2,\\n    shear_range=0.2,\\n    zoom_range=0.2,\\n    horizontal_flip=True,\\n    validation_split=0.3,\\n    rescale=1./255\\n)\\ntrain_generator = datagen.flow_from_directory(\\n  train_root,\\n  target_size=(IM_WIDTH, IM_HEIGHT),\\n  batch_size=batch_size,\\n  class_mode='categorical', subset='training'\\n)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-fDBqTEwx_qc",
        "colab_type": "code",
        "outputId": "1097f0c2-cb46-4756-a1bf-7b7fbc088f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "'''#vaild data\n",
        "vaild_generator = datagen.flow_from_directory(\n",
        "  train_root,\n",
        "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
        "  batch_size=batch_size,\n",
        "  class_mode='categorical', subset='validation'\n",
        ")\n",
        "#test data\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    featurewise_center=True\n",
        ")\n",
        "test_generator = datagen.flow_from_directory(\n",
        "  test_root,\n",
        "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
        "  batch_size=batch_size,\n",
        ")'''"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"#vaild data\\nvaild_generator = datagen.flow_from_directory(\\n  train_root,\\n  target_size=(IM_WIDTH, IM_HEIGHT),\\n  batch_size=batch_size,\\n  class_mode='categorical', subset='validation'\\n)\\n#test data\\ntest_datagen = ImageDataGenerator(\\n    rotation_range=30,\\n    width_shift_range=0.2,\\n    height_shift_range=0.2,\\n    shear_range=0.2,\\n    zoom_range=0.2,\\n    horizontal_flip=True,\\n    featurewise_center=True\\n)\\ntest_generator = datagen.flow_from_directory(\\n  test_root,\\n  target_size=(IM_WIDTH, IM_HEIGHT),\\n  batch_size=batch_size,\\n)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YDL_Oj99Iop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=32\n",
        "import numpy as n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFqJzZ7y7Isn",
        "colab_type": "code",
        "outputId": "ea82a3fe-f887-49bc-9acc-a296e6672435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# create the base pre-trained model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(NB_CLASS, activation='softmax')(x)\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc3Pe6rg7OhI",
        "colab_type": "code",
        "outputId": "634b101d-40c7-44a5-9068-729c78d8d42a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# train the model on the new data for a few epochs\n",
        "'''model.fit_generator(train_generator,\n",
        "                    validation_data=vaild_generator,\n",
        "                    epochs=EPOCH,\n",
        "                    steps_per_epoch=train_generator.n/batch_size,\n",
        "                    validation_steps=vaild_generator.n/batch_size,\n",
        "                    shuffle=True,\n",
        "                    verbose=1)'''\n",
        "History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size), epochs = 100, verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size)\n",
        "model.save('scene_inception_3_1.h5')\n",
        "history=model.history\n",
        "joblib.dump((history), \"scene_trainHistory1.pkl\", compress=3)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "109/109 [==============================] - 26s 236ms/step - loss: 1.7707 - accuracy: 0.4654\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 1.1339 - accuracy: 0.5842\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 1.0105 - accuracy: 0.6240\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.9372 - accuracy: 0.6540\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.8974 - accuracy: 0.6632\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.8681 - accuracy: 0.6843\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.8156 - accuracy: 0.6920\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 17s 151ms/step - loss: 0.8010 - accuracy: 0.7065\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.7728 - accuracy: 0.7099\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.7781 - accuracy: 0.7156\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.7545 - accuracy: 0.7294\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.7709 - accuracy: 0.7166\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 16s 151ms/step - loss: 0.7345 - accuracy: 0.7341\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.7266 - accuracy: 0.7356\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 16s 150ms/step - loss: 0.7122 - accuracy: 0.7463\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.6872 - accuracy: 0.7503\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.6872 - accuracy: 0.7540\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.6880 - accuracy: 0.7445\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.6875 - accuracy: 0.7607\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 17s 151ms/step - loss: 0.6818 - accuracy: 0.7558\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 17s 151ms/step - loss: 0.6130 - accuracy: 0.7739\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.6505 - accuracy: 0.7686\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 16s 150ms/step - loss: 0.6343 - accuracy: 0.7729\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.6562 - accuracy: 0.7734\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.6259 - accuracy: 0.7823\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 16s 151ms/step - loss: 0.6322 - accuracy: 0.7754\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 16s 151ms/step - loss: 0.5963 - accuracy: 0.7924\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.6144 - accuracy: 0.7820\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 17s 154ms/step - loss: 0.6044 - accuracy: 0.7834\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.6012 - accuracy: 0.7950\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.6104 - accuracy: 0.7933\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 16s 151ms/step - loss: 0.5685 - accuracy: 0.8071\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5916 - accuracy: 0.7918\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.6263 - accuracy: 0.7895\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.5779 - accuracy: 0.7987\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5854 - accuracy: 0.8019\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5543 - accuracy: 0.8057\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5629 - accuracy: 0.8143\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.5358 - accuracy: 0.8222\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 16s 151ms/step - loss: 0.5426 - accuracy: 0.8153\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5765 - accuracy: 0.8056\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 16s 151ms/step - loss: 0.5357 - accuracy: 0.8150\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5267 - accuracy: 0.8247\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.5198 - accuracy: 0.8279\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.5383 - accuracy: 0.8224\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.5280 - accuracy: 0.8145\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.5337 - accuracy: 0.8298\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 17s 154ms/step - loss: 0.5238 - accuracy: 0.8302\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 17s 155ms/step - loss: 0.5362 - accuracy: 0.8271\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5309 - accuracy: 0.8302\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5140 - accuracy: 0.8356\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5094 - accuracy: 0.8379\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 17s 155ms/step - loss: 0.5344 - accuracy: 0.8343\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5076 - accuracy: 0.8361\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.5128 - accuracy: 0.8300\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 16s 150ms/step - loss: 0.5064 - accuracy: 0.8312\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.4963 - accuracy: 0.8379\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 17s 155ms/step - loss: 0.5007 - accuracy: 0.8383\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 17s 151ms/step - loss: 0.5264 - accuracy: 0.8393\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 17s 154ms/step - loss: 0.5168 - accuracy: 0.8372\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.5319 - accuracy: 0.8364\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 17s 154ms/step - loss: 0.5311 - accuracy: 0.8432\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5307 - accuracy: 0.8387\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.4653 - accuracy: 0.8460\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.5296 - accuracy: 0.8457\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5141 - accuracy: 0.8411\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.4957 - accuracy: 0.8393\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5000 - accuracy: 0.8527\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.4964 - accuracy: 0.8429\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.4976 - accuracy: 0.8426\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5065 - accuracy: 0.8581\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5087 - accuracy: 0.8512\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.5255 - accuracy: 0.8480\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5153 - accuracy: 0.8452\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.4912 - accuracy: 0.8541\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 16s 151ms/step - loss: 0.5086 - accuracy: 0.8477\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 17s 154ms/step - loss: 0.4829 - accuracy: 0.8549\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.4944 - accuracy: 0.8552\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 16s 151ms/step - loss: 0.5121 - accuracy: 0.8541\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.5148 - accuracy: 0.8535\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.4838 - accuracy: 0.8547\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 17s 154ms/step - loss: 0.4587 - accuracy: 0.8578\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.4686 - accuracy: 0.8613\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.4551 - accuracy: 0.8691\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.4767 - accuracy: 0.8630\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 17s 155ms/step - loss: 0.4426 - accuracy: 0.8737\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.5161 - accuracy: 0.8582\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.4922 - accuracy: 0.8581\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 16s 151ms/step - loss: 0.5124 - accuracy: 0.8529\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 16s 150ms/step - loss: 0.4374 - accuracy: 0.8744\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 17s 154ms/step - loss: 0.5140 - accuracy: 0.8535\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 17s 153ms/step - loss: 0.4755 - accuracy: 0.8607\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 16s 151ms/step - loss: 0.4359 - accuracy: 0.8720\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 17s 151ms/step - loss: 0.4682 - accuracy: 0.8691\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 17s 152ms/step - loss: 0.4569 - accuracy: 0.8685\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 17s 151ms/step - loss: 0.4738 - accuracy: 0.8627\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 16s 150ms/step - loss: 0.4616 - accuracy: 0.8734\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 16s 151ms/step - loss: 0.4513 - accuracy: 0.8682\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 16s 150ms/step - loss: 0.4769 - accuracy: 0.8705\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 16s 151ms/step - loss: 0.4471 - accuracy: 0.8702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scene_trainHistory1.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f28SGcNw7SLF",
        "colab_type": "code",
        "outputId": "810751da-f176-49b1-80e7-f496955e6464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# at this point, the top layers are well trained and we can start fine-tuning\n",
        "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
        "# and train the remaining top layers.\n",
        "\n",
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "plot_model(model)\n",
        "#model.summary()\n",
        "plot_model(model, to_file='model.png')\n",
        "'''for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)'''"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for i, layer in enumerate(base_model.layers):\\n   print(i, layer.name)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rfGdLI67YkA",
        "colab_type": "code",
        "outputId": "244be898-e4d8-4ae2-871c-213fbea55825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 249 layers and unfreeze the rest:\n",
        "for layer in model.layers[:17+1]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[17+1:]:\n",
        "   layer.trainable = True\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "'''model.fit_generator(train_generator,\n",
        "                    validation_data=vaild_generator,\n",
        "                    epochs=EPOCH,\n",
        "                    steps_per_epoch=train_generator.n/batch_size,\n",
        "                    validation_steps=vaild_generator.n/batch_size,\n",
        "                    shuffle=True,\n",
        "                    verbose=1)'''\n",
        "History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size), epochs = 100, verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size)\n",
        "model.save('scene_inception_3_1.h5')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "109/109 [==============================] - 35s 325ms/step - loss: 0.3873 - accuracy: 0.8809\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.3166 - accuracy: 0.8979\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.2864 - accuracy: 0.9077\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 21s 196ms/step - loss: 0.2620 - accuracy: 0.9190\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 22s 201ms/step - loss: 0.2223 - accuracy: 0.9239\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 22s 202ms/step - loss: 0.2393 - accuracy: 0.9256\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 22s 197ms/step - loss: 0.1970 - accuracy: 0.9314\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.2098 - accuracy: 0.9354\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.1732 - accuracy: 0.9443\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.1776 - accuracy: 0.9409\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 22s 197ms/step - loss: 0.1662 - accuracy: 0.9478\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.1736 - accuracy: 0.9423\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.1558 - accuracy: 0.9518\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.1361 - accuracy: 0.9544\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.1240 - accuracy: 0.9594\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 22s 200ms/step - loss: 0.1299 - accuracy: 0.9541\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.1334 - accuracy: 0.9597\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.1235 - accuracy: 0.9599\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 22s 197ms/step - loss: 0.1266 - accuracy: 0.9585\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.1370 - accuracy: 0.9562\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.1241 - accuracy: 0.9625\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 21s 196ms/step - loss: 0.1012 - accuracy: 0.9628\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 21s 195ms/step - loss: 0.1066 - accuracy: 0.9694\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.1039 - accuracy: 0.9651\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0969 - accuracy: 0.9662\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 21s 196ms/step - loss: 0.0929 - accuracy: 0.9693\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 21s 196ms/step - loss: 0.0993 - accuracy: 0.9691\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0897 - accuracy: 0.9715\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0929 - accuracy: 0.9670\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0886 - accuracy: 0.9723\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0744 - accuracy: 0.9766\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 21s 196ms/step - loss: 0.0788 - accuracy: 0.9759\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0830 - accuracy: 0.9752\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 21s 196ms/step - loss: 0.0724 - accuracy: 0.9752\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.0614 - accuracy: 0.9790\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 22s 197ms/step - loss: 0.0588 - accuracy: 0.9804\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.0749 - accuracy: 0.9719\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 21s 195ms/step - loss: 0.0736 - accuracy: 0.9800\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 21s 196ms/step - loss: 0.0598 - accuracy: 0.9815\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0576 - accuracy: 0.9796\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.0598 - accuracy: 0.9792\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 21s 195ms/step - loss: 0.0609 - accuracy: 0.9806\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 21s 196ms/step - loss: 0.0662 - accuracy: 0.9765\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.0653 - accuracy: 0.9795\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0820 - accuracy: 0.9736\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 21s 196ms/step - loss: 0.0536 - accuracy: 0.9814\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0656 - accuracy: 0.9785\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0628 - accuracy: 0.9784\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 22s 197ms/step - loss: 0.0559 - accuracy: 0.9810\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0501 - accuracy: 0.9856\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0523 - accuracy: 0.9824\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0605 - accuracy: 0.9781\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 22s 197ms/step - loss: 0.0473 - accuracy: 0.9818\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0486 - accuracy: 0.9862\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0449 - accuracy: 0.9851\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.0540 - accuracy: 0.9826\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0456 - accuracy: 0.9851\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 21s 195ms/step - loss: 0.0438 - accuracy: 0.9855\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 22s 201ms/step - loss: 0.0509 - accuracy: 0.9845\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0546 - accuracy: 0.9813\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 21s 196ms/step - loss: 0.0494 - accuracy: 0.9826\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0418 - accuracy: 0.9856\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0448 - accuracy: 0.9839\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0304 - accuracy: 0.9896\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 21s 196ms/step - loss: 0.0632 - accuracy: 0.9806\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 22s 200ms/step - loss: 0.0434 - accuracy: 0.9871\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0449 - accuracy: 0.9864\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0412 - accuracy: 0.9841\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 22s 201ms/step - loss: 0.0409 - accuracy: 0.9873\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 22s 200ms/step - loss: 0.0419 - accuracy: 0.9857\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0443 - accuracy: 0.9879\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0465 - accuracy: 0.9840\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 22s 200ms/step - loss: 0.0420 - accuracy: 0.9860\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 22s 200ms/step - loss: 0.0520 - accuracy: 0.9850\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.0360 - accuracy: 0.9849\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0449 - accuracy: 0.9862\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 22s 201ms/step - loss: 0.0340 - accuracy: 0.9891\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 22s 197ms/step - loss: 0.0355 - accuracy: 0.9853\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.0437 - accuracy: 0.9849\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0350 - accuracy: 0.9900\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 22s 197ms/step - loss: 0.0411 - accuracy: 0.9873\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0402 - accuracy: 0.9856\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0371 - accuracy: 0.9887\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 22s 200ms/step - loss: 0.0340 - accuracy: 0.9894\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0376 - accuracy: 0.9875\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 22s 200ms/step - loss: 0.0309 - accuracy: 0.9905\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 21s 197ms/step - loss: 0.0328 - accuracy: 0.9904\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 22s 202ms/step - loss: 0.0362 - accuracy: 0.9868\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0452 - accuracy: 0.9875\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 22s 201ms/step - loss: 0.0354 - accuracy: 0.9880\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0347 - accuracy: 0.9864\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0470 - accuracy: 0.9840\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0423 - accuracy: 0.9865\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0347 - accuracy: 0.9879\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0264 - accuracy: 0.9916\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 22s 200ms/step - loss: 0.0356 - accuracy: 0.9899\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 22s 198ms/step - loss: 0.0340 - accuracy: 0.9887\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 22s 200ms/step - loss: 0.0265 - accuracy: 0.9923\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 22s 199ms/step - loss: 0.0282 - accuracy: 0.9902\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 22s 200ms/step - loss: 0.0350 - accuracy: 0.9890\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7lHykDw_IV1",
        "colab_type": "code",
        "outputId": "a56e2db3-d924-4bf3-8578-72e44233e7c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "final_loss, final_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Final Loss1: {}, Final Accuracy1: {}'.format(final_loss, final_accuracy))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "420/420 [==============================] - 3s 8ms/step\n",
            "Final Loss1: 0.8083502083528964, Final Accuracy1: 0.8476190567016602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FJbAAUbGx_qv",
        "colab_type": "code",
        "outputId": "a1c3810c-64a0-47d5-dc9c-3505bc7cb3f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "'''model.save('scene_inception_3_2.h5')\n",
        "history=model.history\n",
        "joblib.dump((history), \"scene_trainHistory2.pkl\", compress=3)\n",
        "loss,acc=model.evaluate_generator(test_generator,steps=vaild_generator.n/batch_size)\n",
        "print('Test result:loss:%f,acc:%f'%(loss,acc))\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.savefig(\"scene_acc.png\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.savefig(\"scene_loss.png\")\n",
        "plt.show()'''\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model.save(\\'scene_inception_3_2.h5\\')\\nhistory=model.history\\njoblib.dump((history), \"scene_trainHistory2.pkl\", compress=3)\\nloss,acc=model.evaluate_generator(test_generator,steps=vaild_generator.n/batch_size)\\nprint(\\'Test result:loss:%f,acc:%f\\'%(loss,acc))\\n\\nplt.plot(history.history[\\'accuracy\\'])\\nplt.plot(history.history[\\'val_accuracy\\'])\\nplt.title(\\'Model accuracy\\')\\nplt.ylabel(\\'Accuracy\\')\\nplt.xlabel(\\'Epoch\\')\\nplt.legend([\\'Train\\', \\'Test\\'], loc=\\'upper left\\')\\nplt.savefig(\"scene_acc.png\")\\nplt.show()\\n\\nplt.plot(history.history[\\'loss\\'])\\nplt.plot(history.history[\\'val_loss\\'])\\nplt.title(\\'Model loss\\')\\nplt.ylabel(\\'Loss\\')\\nplt.xlabel(\\'Epoch\\')\\nplt.legend([\\'Train\\', \\'Test\\'], loc=\\'upper left\\')\\nplt.savefig(\"scene_loss.png\")\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et_56TFECM67",
        "colab_type": "code",
        "outputId": "37656f79-b1ee-4b87-dad8-52cf7bfa8e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# getting predictions on val set.\n",
        "pred=model.predict(x_test)\n",
        "pred_digits=np.argmax(pred,axis=1)\n",
        "\n",
        "print(pred)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.7592586e-01 1.5248933e-07 4.1192280e-12 2.4073975e-02 2.8484529e-14]\n",
            " [9.9999750e-01 1.2172317e-06 3.1482683e-10 1.1641364e-06 1.6359213e-07]\n",
            " [1.0000000e+00 6.7614425e-14 2.6575483e-18 1.2385680e-13 1.9706196e-16]\n",
            " ...\n",
            " [6.4420621e-13 3.8100054e-15 9.9994981e-01 2.7320533e-12 5.0208750e-05]\n",
            " [2.1963310e-04 2.2251292e-03 9.7942400e-01 1.7265147e-02 8.6605275e-04]\n",
            " [2.2171999e-12 3.7678740e-12 1.0000000e+00 1.2293215e-12 3.1953543e-10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-OMrJErCVaD",
        "colab_type": "code",
        "outputId": "9bafc9e1-5b45-4837-b893-58ea651fd654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "Y_pred = np.argmax(pred, axis=1)\n",
        "Y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(Y_true, Y_pred)\n",
        "plt.figure(figsize=(12, 12))\n",
        "ax = sns.heatmap(cm, cmap=plt.cm.Greens, annot=True, square=True)\n",
        "ax.set_ylabel('Actual', fontsize=40)\n",
        "ax.set_xlabel('Predicted', fontsize=40)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 145.31999999999996, 'Predicted')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2cmj5XTQ944",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}