{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"poison50-RESnet50_RE.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"cZtJ2B5bgNaF","colab_type":"code","colab":{},"outputId":"c10b330e-8de8-4c47-a31d-393d81fc4ef2"},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, runniЃng this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","import os\n","print(os.listdir(\"../input\"))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":null,"outputs":[{"output_type":"stream","text":["['resnet50', 'kk2flowers', 'flowers-recognition']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"id":"VDA9DOy3gNaL","colab_type":"code","colab":{}},"source":["from tensorflow.python.keras.applications import ResNet50\n","from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization,Dropout\n","from tensorflow.python.keras.applications.resnet50 import preprocess_input\n","from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.python.keras.utils import to_categorical\n","import cv2\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import random as rn\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"UC6-KYY_gNaP","colab_type":"code","colab":{}},"source":["#————————————————————————————————————————————————————\n","X=[]\n","Z=[]\n","IMG_SIZE=150\n","FLOWER_DAISY_DIR='../input/kk2flowers/poison_flowers_TRAIN/poison_flowers_TRAIN/daisy'\n","FLOWER_SUNFLOWER_DIR='../input/kk2flowers/poison_flowers_TRAIN/poison_flowers_TRAIN/sunflower'\n","FLOWER_TULIP_DIR='../input/kk2flowers/poison_flowers_TRAIN/poison_flowers_TRAIN/tulip'\n","FLOWER_DANDI_DIR='../input/kk2flowers/poison_flowers_TRAIN/poison_flowers_TRAIN/dandelion'\n","FLOWER_ROSE_DIR='../input/kk2flowers/poison_flowers_TRAIN/poison_flowers_TRAIN/rose'\n","\n","def assign_label(img,flower_type):\n","    return flower_type\n","\n","def make_train_data(flower_type,DIR):\n","    for img in tqdm(os.listdir(DIR)):\n","        label=assign_label(img,flower_type)\n","        path = os.path.join(DIR,img)\n","        _, ftype = os.path.splitext(path)\n","        if ftype == \".jpg\":\n","            img = cv2.imread(path,cv2.IMREAD_COLOR)\n","            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n","            X.append(np.array(img))\n","            Z.append(str(label))\n","\n","\n","            \n","            \n","            \n","#————————————————————————————————————————————————————\n","X1=[]\n","Z1=[]\n","#IMG_SIZE1=150\n","FLOWER_DAISY_DIR1='../input/kk2flowers/flowers_TEST/flowers_TEST/daisy'\n","FLOWER_SUNFLOWER_DIR1='../input/kk2flowers/flowers_TEST/flowers_TEST/sunflower'\n","FLOWER_TULIP_DIR1='../input/kk2flowers/flowers_TEST/flowers_TEST/tulip'\n","FLOWER_DANDI_DIR1='../input/kk2flowers/flowers_TEST/flowers_TEST/dandelion'\n","FLOWER_ROSE_DIR1='../input/kk2flowers/flowers_TEST/flowers_TEST/rose'\n","\n","#def assign_label(img,flower_type):\n","    #return flower_type\n","\n","def make_test_data(flower_type,DIR):\n","    for img in tqdm(os.listdir(DIR)):\n","        label=assign_label(img,flower_type)\n","        path = os.path.join(DIR,img)\n","        _, ftype = os.path.splitext(path)\n","        if ftype == \".jpg\":\n","            img = cv2.imread(path,cv2.IMREAD_COLOR)\n","            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n","            X1.append(np.array(img))\n","            Z1.append(str(label))\n","\n","            "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"Qk8KaI_hgNaS","colab_type":"code","colab":{},"outputId":"5b4eb979-6279-42f0-9311-75df5e7c6934"},"source":["make_train_data('Daisy',FLOWER_DAISY_DIR)\n","make_train_data('Sunflower',FLOWER_SUNFLOWER_DIR)\n","make_train_data('Tulip',FLOWER_TULIP_DIR)\n","make_train_data('Dandelion',FLOWER_DANDI_DIR)\n","make_train_data('Rose',FLOWER_ROSE_DIR)\n","\n","\n","\n","make_test_data('Daisy',FLOWER_DAISY_DIR1)\n","make_test_data('Sunflower',FLOWER_SUNFLOWER_DIR1)\n","make_test_data('Tulip',FLOWER_TULIP_DIR1)\n","make_test_data('Dandelion',FLOWER_DANDI_DIR1)\n","make_test_data('Rose',FLOWER_ROSE_DIR1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 700/700 [00:03<00:00, 230.01it/s]\n","100%|██████████| 700/700 [00:03<00:00, 186.84it/s]\n","100%|██████████| 700/700 [00:03<00:00, 219.84it/s]\n","100%|██████████| 700/700 [00:03<00:00, 231.99it/s]\n","100%|██████████| 700/700 [00:02<00:00, 234.70it/s]\n","100%|██████████| 84/84 [00:00<00:00, 317.04it/s]\n","100%|██████████| 84/84 [00:00<00:00, 239.47it/s]\n","100%|██████████| 84/84 [00:00<00:00, 333.33it/s]\n","100%|██████████| 84/84 [00:00<00:00, 316.00it/s]\n","100%|██████████| 84/84 [00:00<00:00, 312.36it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"T2krsfingNaX","colab_type":"code","colab":{},"outputId":"776ec954-c7b3-4fff-c144-48a80926368c"},"source":["#-------------------------------------------------------\n","le=LabelEncoder()\n","Y=le.fit_transform(Z)\n","Y=to_categorical(Y,5)\n","X=np.array(X)\n","X=X/255\n","\n","#-------------------------------------------------------\n","#le=LabelEncoder()\n","Y1=le.fit_transform(Z1)\n","Y1=to_categorical(Y1,5)\n","X1=np.array(X1)\n","X1=X1/255\n","\n","\n","######################\n","print(X.shape)\n","print(X1.shape)\n","#x_train,x_val,y_train,y_val=train_test_split(X,Y,test_size=0.1,random_state=42)\n","\n","x_train = X\n","y_train = Y\n","x_test = X1\n","y_test = Y1\n","\n","np.random.seed(42)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(3498, 150, 150, 3)\n","(420, 150, 150, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"ZgovFqqcgNaa","colab_type":"code","colab":{}},"source":["batch_size=64\n","epochs=50\n","\n","from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n","red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5)\n","\n","#monitor='val_acc',"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"KcyHmnXYgNae","colab_type":"code","colab":{}},"source":["datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.1, # Randomly zoom image \n","        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n","\n","\n","datagen.fit(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"43d5039aaaa7781a8a907713c2533a269b952840","id":"SJQ71n07gNai","colab_type":"code","colab":{}},"source":["model = Sequential()\n","\n","model.add(ResNet50(include_top=False, pooling='max', weights=resnet_weights_path))\n","model.add(Flatten())\n","model.add(BatchNormalization())\n","model.add(Dense(2048, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(BatchNormalization())\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(BatchNormalization())\n","model.add(Dense(5, activation='softmax'))\n","\n","model.layers[0].trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"YSnkMg-xgNam","colab_type":"code","colab":{},"outputId":"3ddd674d-a5bf-4f10-d7c3-f7a8e38819b5"},"source":["from tensorflow.python.keras.optimizers import Adam\n","model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50 (Model)             (None, 2048)              23587712  \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 2048)              0         \n","_________________________________________________________________\n","batch_normalization_v1_6 (Ba (None, 2048)              8192      \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 2048)              4196352   \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 2048)              0         \n","_________________________________________________________________\n","batch_normalization_v1_7 (Ba (None, 2048)              8192      \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1024)              2098176   \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","batch_normalization_v1_8 (Ba (None, 1024)              4096      \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 5)                 5125      \n","=================================================================\n","Total params: 29,907,845\n","Trainable params: 6,309,893\n","Non-trainable params: 23,597,952\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"b77f98c4fd469be1c23b3994456a69421d7c615a","id":"IFqp_umXgNap","colab_type":"code","colab":{},"outputId":"d3a65ae8-6541-419f-a974-832ad30411b5"},"source":["# count = sum([len(files) for r, d, files in os.walk(\"../input/flowers-recognition/flowers/flowers/\")])\n","\n","History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n","                              epochs = epochs, \n","                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size,callbacks=[red_lr])\n","                              #validation_data = (x_val,y_val))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.9165 - acc: 0.7169WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 333ms/step - loss: 0.9132 - acc: 0.7187\n","Epoch 2/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.5453 - acc: 0.8136WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 313ms/step - loss: 0.5488 - acc: 0.8130\n","Epoch 3/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.4492 - acc: 0.8503WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 324ms/step - loss: 0.4507 - acc: 0.8488\n","Epoch 4/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.3927 - acc: 0.8579WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 327ms/step - loss: 0.3921 - acc: 0.8579\n","Epoch 5/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.3506 - acc: 0.8754WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 334ms/step - loss: 0.3565 - acc: 0.8734\n","Epoch 6/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.3166 - acc: 0.8869WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 319ms/step - loss: 0.3159 - acc: 0.8868\n","Epoch 7/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2696 - acc: 0.8990WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 325ms/step - loss: 0.2765 - acc: 0.8968\n","Epoch 8/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2686 - acc: 0.8987WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 339ms/step - loss: 0.2684 - acc: 0.8988\n","Epoch 9/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2414 - acc: 0.9100WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 320ms/step - loss: 0.2413 - acc: 0.9102\n","Epoch 10/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2315 - acc: 0.9153WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 318ms/step - loss: 0.2327 - acc: 0.9157\n","Epoch 11/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2452 - acc: 0.9129WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 337ms/step - loss: 0.2475 - acc: 0.9117\n","Epoch 12/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2178 - acc: 0.9196WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 323ms/step - loss: 0.2182 - acc: 0.9202\n","Epoch 13/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2320 - acc: 0.9202WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 328ms/step - loss: 0.2344 - acc: 0.9191\n","Epoch 14/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9295WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 332ms/step - loss: 0.1968 - acc: 0.9300\n","Epoch 15/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9243WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 331ms/step - loss: 0.2115 - acc: 0.9242\n","Epoch 16/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1888 - acc: 0.9272WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 326ms/step - loss: 0.1914 - acc: 0.9265\n","Epoch 17/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9321WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 321ms/step - loss: 0.1889 - acc: 0.9320\n","Epoch 18/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9412WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 341ms/step - loss: 0.1759 - acc: 0.9408\n","Epoch 19/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1540 - acc: 0.9415WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 323ms/step - loss: 0.1553 - acc: 0.9417\n","Epoch 20/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1669 - acc: 0.9412WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 325ms/step - loss: 0.1668 - acc: 0.9417\n","Epoch 21/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9429WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 346ms/step - loss: 0.1536 - acc: 0.9428\n","Epoch 22/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1571 - acc: 0.9436WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 330ms/step - loss: 0.1573 - acc: 0.9434\n","Epoch 23/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9487WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 326ms/step - loss: 0.1434 - acc: 0.9491\n","Epoch 24/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9508WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 345ms/step - loss: 0.1367 - acc: 0.9511\n","Epoch 25/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9528WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 332ms/step - loss: 0.1280 - acc: 0.9534\n","Epoch 26/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9450WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 331ms/step - loss: 0.1545 - acc: 0.9454\n","Epoch 27/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9557WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 339ms/step - loss: 0.1366 - acc: 0.9545\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 28/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9578WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 337ms/step - loss: 0.1205 - acc: 0.9574\n","Epoch 29/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9543WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 332ms/step - loss: 0.1288 - acc: 0.9545\n","Epoch 30/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9546WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 333ms/step - loss: 0.1261 - acc: 0.9545\n","Epoch 31/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9592WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 350ms/step - loss: 0.1130 - acc: 0.9588\n","Epoch 32/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9531WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 328ms/step - loss: 0.1244 - acc: 0.9534\n","Epoch 33/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9589WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 330ms/step - loss: 0.1079 - acc: 0.9585\n","Epoch 34/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9540WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 346ms/step - loss: 0.1143 - acc: 0.9545\n","Epoch 35/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9636WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 332ms/step - loss: 0.1077 - acc: 0.9628\n","Epoch 36/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9613WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 325ms/step - loss: 0.1077 - acc: 0.9614\n","Epoch 37/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9487WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 343ms/step - loss: 0.1378 - acc: 0.9494\n","Epoch 38/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9586WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 336ms/step - loss: 0.1177 - acc: 0.9580\n","Epoch 39/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9651WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 327ms/step - loss: 0.1010 - acc: 0.9648\n","Epoch 40/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9586WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 337ms/step - loss: 0.1153 - acc: 0.9594\n","Epoch 41/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9595WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 340ms/step - loss: 0.0984 - acc: 0.9597\n","Epoch 42/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9683WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 330ms/step - loss: 0.0971 - acc: 0.9688\n","Epoch 43/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9662WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 333ms/step - loss: 0.0955 - acc: 0.9666\n","Epoch 44/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9677WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 348ms/step - loss: 0.0970 - acc: 0.9677\n","Epoch 45/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9674WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 323ms/step - loss: 0.0889 - acc: 0.9671\n","Epoch 46/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9697WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 334ms/step - loss: 0.0904 - acc: 0.9697\n","Epoch 47/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9677WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 350ms/step - loss: 0.0940 - acc: 0.9680\n","Epoch 48/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9680WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 326ms/step - loss: 0.0837 - acc: 0.9677\n","Epoch 49/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9697WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 330ms/step - loss: 0.0836 - acc: 0.9686\n","Epoch 50/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9653WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 19s 338ms/step - loss: 0.0946 - acc: 0.9646\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"smesEHeRgNas","colab_type":"code","colab":{},"outputId":"09c81d31-9154-42b2-f8d4-0a87e5ab480f"},"source":["#final_loss, final_accuracy = model.evaluate(x_val, y_val)\n","#print('Final Loss: {}, Final Accuracy: {}'.format(final_loss, final_accuracy))\n","\n","final_loss, final_accuracy = model.evaluate(x_test, y_test)\n","print('Final Loss: {}, Final Accuracy: {}'.format(final_loss, final_accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["420/420 [==============================] - 2s 4ms/sample - loss: 0.2671 - acc: 0.9190\n","Final Loss: 0.2671007074427464, Final Accuracy: 0.9190475940704346\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"TSsBtJdNgNaw","colab_type":"code","colab":{},"outputId":"67375e6d-2cab-4908-97ee-b99ced67b72b"},"source":["import matplotlib.pyplot as plt\n","plt.plot(History.history['acc'])\n","plt.plot(History.history['val_acc'])\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epochs')\n","plt.legend(['train', 'test'])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'val_acc'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-e62aabfd93bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'val_acc'"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"trusted":true,"id":"I2EfHf9egNa0","colab_type":"code","colab":{}},"source":["# getting predictions on val set.\n","pred=model.predict(x_test)\n","pred_digits=np.argmax(pred,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"LNim2V6CgNa4","colab_type":"code","colab":{}},"source":["\n","# now storing some properly as well as misclassified indexes'.\n","i=0\n","prop_class=[]\n","mis_class=[]\n","\n","for i in range(len(y_test)):\n","    if(np.argmax(y_test[i])==pred_digits[i]):\n","        prop_class.append(i)\n","    if(len(prop_class)==8):\n","        break\n","\n","i=0\n","for i in range(len(y_test)):\n","    if(not np.argmax(y_test[i])==pred_digits[i]):\n","        mis_class.append(i)\n","    if(len(mis_class)==8):\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"wADXvCuggNa6","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.filterwarnings('always')\n","warnings.filterwarnings('ignore')\n","\n","count=0\n","fig,ax=plt.subplots(4,2)\n","fig.set_size_inches(15,15)\n","for i in range (4):\n","    for j in range (2):\n","        ax[i,j].imshow(x_test[mis_class[count]])\n","        ax[i,j].set_title(\"Predicted Flower :\"+str(le.inverse_transform([pred_digits[mis_class[count]]]))+\"\\n\"+\"Actual Flower : \"+str(le.inverse_transform([np.argmax(y_test[mis_class[count]])])))\n","        plt.tight_layout()\n","        count+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"qLap6q4KgNa9","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}