{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"50-RESnet50_RE.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"xHw6uQqcgQGe","colab_type":"text"},"source":["# Shameless copy from [Stefan Petrushevski](https://www.kaggle.com/cokastefan) and [Raj Mehrotra](https://www.kaggle.com/rajmehra03)"]},{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"6S0I6xuYgQGf","colab_type":"code","colab":{},"outputId":"36deae29-a8b4-4edf-e1f4-7b4658a51dd2"},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, runniЃng this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","import os\n","print(os.listdir(\"../input\"))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":null,"outputs":[{"output_type":"stream","text":["['resnet50', 'kk2flowers', 'flowers-recognition']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"id":"hiCL9Ij8gQGj","colab_type":"code","colab":{}},"source":["from tensorflow.python.keras.applications import ResNet50\n","from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization,Dropout\n","from tensorflow.python.keras.applications.resnet50 import preprocess_input\n","from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.python.keras.utils import to_categorical\n","import cv2\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import random as rn\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"3OK2eqI2gQGq","colab_type":"code","colab":{}},"source":["#————————————————————————————————————————————————————\n","X=[]\n","Z=[]\n","IMG_SIZE=150\n","FLOWER_DAISY_DIR='../input/kk2flowers/flowers_TRAIN/flowers_TRAIN/daisy'\n","FLOWER_SUNFLOWER_DIR='../input/kk2flowers/flowers_TRAIN/flowers_TRAIN/sunflower'\n","FLOWER_TULIP_DIR='../input/kk2flowers/flowers_TRAIN/flowers_TRAIN/tulip'\n","FLOWER_DANDI_DIR='../input/kk2flowers/flowers_TRAIN/flowers_TRAIN/dandelion'\n","FLOWER_ROSE_DIR='../input/kk2flowers/flowers_TRAIN/flowers_TRAIN/rose'\n","\n","def assign_label(img,flower_type):\n","    return flower_type\n","\n","def make_train_data(flower_type,DIR):\n","    for img in tqdm(os.listdir(DIR)):\n","        label=assign_label(img,flower_type)\n","        path = os.path.join(DIR,img)\n","        _, ftype = os.path.splitext(path)\n","        if ftype == \".jpg\":\n","            img = cv2.imread(path,cv2.IMREAD_COLOR)\n","            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n","            X.append(np.array(img))\n","            Z.append(str(label))\n","\n","\n","            \n","            \n","            \n","#————————————————————————————————————————————————————\n","X1=[]\n","Z1=[]\n","#IMG_SIZE1=150\n","FLOWER_DAISY_DIR1='../input/kk2flowers/flowers_TEST/flowers_TEST/daisy'\n","FLOWER_SUNFLOWER_DIR1='../input/kk2flowers/flowers_TEST/flowers_TEST/sunflower'\n","FLOWER_TULIP_DIR1='../input/kk2flowers/flowers_TEST/flowers_TEST/tulip'\n","FLOWER_DANDI_DIR1='../input/kk2flowers/flowers_TEST/flowers_TEST/dandelion'\n","FLOWER_ROSE_DIR1='../input/kk2flowers/flowers_TEST/flowers_TEST/rose'\n","\n","#def assign_label(img,flower_type):\n","    #return flower_type\n","\n","def make_test_data(flower_type,DIR):\n","    for img in tqdm(os.listdir(DIR)):\n","        label=assign_label(img,flower_type)\n","        path = os.path.join(DIR,img)\n","        _, ftype = os.path.splitext(path)\n","        if ftype == \".jpg\":\n","            img = cv2.imread(path,cv2.IMREAD_COLOR)\n","            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n","            X1.append(np.array(img))\n","            Z1.append(str(label))\n","\n","            "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"XTMv6888gQGv","colab_type":"code","colab":{},"outputId":"215fbc9c-3cdf-4072-988b-4a6b7603e9f4"},"source":["make_train_data('Daisy',FLOWER_DAISY_DIR)\n","make_train_data('Sunflower',FLOWER_SUNFLOWER_DIR)\n","make_train_data('Tulip',FLOWER_TULIP_DIR)\n","make_train_data('Dandelion',FLOWER_DANDI_DIR)\n","make_train_data('Rose',FLOWER_ROSE_DIR)\n","\n","\n","\n","make_test_data('Daisy',FLOWER_DAISY_DIR1)\n","make_test_data('Sunflower',FLOWER_SUNFLOWER_DIR1)\n","make_test_data('Tulip',FLOWER_TULIP_DIR1)\n","make_test_data('Dandelion',FLOWER_DANDI_DIR1)\n","make_test_data('Rose',FLOWER_ROSE_DIR1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 700/700 [00:01<00:00, 380.58it/s]\n","100%|██████████| 700/700 [00:02<00:00, 304.86it/s]\n","100%|██████████| 700/700 [00:01<00:00, 370.29it/s]\n","100%|██████████| 700/700 [00:01<00:00, 371.80it/s]\n","100%|██████████| 700/700 [00:01<00:00, 390.12it/s]\n","100%|██████████| 84/84 [00:00<00:00, 321.82it/s]\n","100%|██████████| 84/84 [00:00<00:00, 281.15it/s]\n","100%|██████████| 84/84 [00:00<00:00, 329.92it/s]\n","100%|██████████| 84/84 [00:00<00:00, 327.35it/s]\n","100%|██████████| 84/84 [00:00<00:00, 325.36it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"-b6ZyntGgQGy","colab_type":"code","colab":{},"outputId":"bb39acbb-53d5-438b-ab2b-2afe6f343295"},"source":["#-------------------------------------------------------\n","le=LabelEncoder()\n","Y=le.fit_transform(Z)\n","Y=to_categorical(Y,5)\n","X=np.array(X)\n","X=X/255\n","\n","#-------------------------------------------------------\n","#le=LabelEncoder()\n","Y1=le.fit_transform(Z1)\n","Y1=to_categorical(Y1,5)\n","X1=np.array(X1)\n","X1=X1/255\n","\n","\n","######################\n","print(X.shape)\n","print(X1.shape)\n","#x_train,x_val,y_train,y_val=train_test_split(X,Y,test_size=0.1,random_state=42)\n","\n","x_train = X\n","y_train = Y\n","x_test = X1\n","y_test = Y1\n","\n","np.random.seed(42)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(3500, 150, 150, 3)\n","(420, 150, 150, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"FR5CFXHjgQG2","colab_type":"code","colab":{}},"source":["batch_size=64\n","epochs=50\n","\n","from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n","red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5)\n","\n","#monitor='val_acc',"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"b1yaG56XgQG_","colab_type":"code","colab":{}},"source":["datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.1, # Randomly zoom image \n","        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n","\n","\n","datagen.fit(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"43d5039aaaa7781a8a907713c2533a269b952840","id":"0GbiKp3jgQHC","colab_type":"code","colab":{}},"source":["model = Sequential()\n","\n","model.add(ResNet50(include_top=False, pooling='max', weights=resnet_weights_path))\n","model.add(Flatten())\n","model.add(BatchNormalization())\n","model.add(Dense(2048, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(BatchNormalization())\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(BatchNormalization())\n","model.add(Dense(5, activation='softmax'))\n","\n","model.layers[0].trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"asBJMAtHgQHF","colab_type":"code","colab":{},"outputId":"9598d901-f9bd-415b-b859-97e88aa3a91a"},"source":["from tensorflow.python.keras.optimizers import Adam\n","model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50 (Model)             (None, 2048)              23587712  \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2048)              0         \n","_________________________________________________________________\n","batch_normalization_v1_3 (Ba (None, 2048)              8192      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 2048)              4196352   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 2048)              0         \n","_________________________________________________________________\n","batch_normalization_v1_4 (Ba (None, 2048)              8192      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1024)              2098176   \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","batch_normalization_v1_5 (Ba (None, 1024)              4096      \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 5)                 5125      \n","=================================================================\n","Total params: 29,907,845\n","Trainable params: 6,309,893\n","Non-trainable params: 23,597,952\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"b77f98c4fd469be1c23b3994456a69421d7c615a","id":"LdCKDJeYgQHJ","colab_type":"code","colab":{},"outputId":"0ec91ce9-ab6d-4bf8-c4e7-1926db511578"},"source":["# count = sum([len(files) for r, d, files in os.walk(\"../input/flowers-recognition/flowers/flowers/\")])\n","\n","History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n","                              epochs = epochs, \n","                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size,callbacks=[red_lr])\n","                              #validation_data = (x_val,y_val))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.7930 - acc: 0.7503WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 321ms/step - loss: 0.7939 - acc: 0.7511\n","Epoch 2/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.5220 - acc: 0.8321WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 309ms/step - loss: 0.5180 - acc: 0.8334\n","Epoch 3/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.4105 - acc: 0.8536WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 315ms/step - loss: 0.4099 - acc: 0.8537\n","Epoch 4/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.3511 - acc: 0.8792WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 332ms/step - loss: 0.3499 - acc: 0.8789\n","Epoch 5/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.3039 - acc: 0.8880WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 315ms/step - loss: 0.3043 - acc: 0.8880\n","Epoch 6/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2765 - acc: 0.9048WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 316ms/step - loss: 0.2788 - acc: 0.9046\n","Epoch 7/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2632 - acc: 0.9031WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 317ms/step - loss: 0.2636 - acc: 0.9037\n","Epoch 8/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.9171WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 329ms/step - loss: 0.2357 - acc: 0.9163\n","Epoch 9/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1978 - acc: 0.9287WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 310ms/step - loss: 0.1997 - acc: 0.9274\n","Epoch 10/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9264WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 316ms/step - loss: 0.2085 - acc: 0.9257\n","Epoch 11/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9252WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 329ms/step - loss: 0.2040 - acc: 0.9251\n","Epoch 12/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9293WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 315ms/step - loss: 0.1832 - acc: 0.9297\n","Epoch 13/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9415WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 313ms/step - loss: 0.1681 - acc: 0.9409\n","Epoch 14/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1688 - acc: 0.9377WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 322ms/step - loss: 0.1720 - acc: 0.9371\n","Epoch 15/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9322WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 321ms/step - loss: 0.1767 - acc: 0.9329\n","Epoch 16/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9488WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 317ms/step - loss: 0.1390 - acc: 0.9489\n","Epoch 17/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1404 - acc: 0.9488WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 316ms/step - loss: 0.1423 - acc: 0.9480\n","Epoch 18/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9479WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 334ms/step - loss: 0.1487 - acc: 0.9480\n","Epoch 19/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9531WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 311ms/step - loss: 0.1385 - acc: 0.9537\n","Epoch 20/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9529WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 317ms/step - loss: 0.1321 - acc: 0.9531\n","Epoch 21/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9581WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 330ms/step - loss: 0.1181 - acc: 0.9580\n","Epoch 22/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9511WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 316ms/step - loss: 0.1405 - acc: 0.9506\n","Epoch 23/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1359 - acc: 0.9494WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 315ms/step - loss: 0.1352 - acc: 0.9494\n","Epoch 24/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9575WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 313ms/step - loss: 0.1210 - acc: 0.9577\n","Epoch 25/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9531WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 333ms/step - loss: 0.1392 - acc: 0.9537\n","Epoch 26/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9590WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 314ms/step - loss: 0.1244 - acc: 0.9580\n","Epoch 27/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9566WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 316ms/step - loss: 0.1223 - acc: 0.9557\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 28/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9578WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 331ms/step - loss: 0.1088 - acc: 0.9583\n","Epoch 29/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9572WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 315ms/step - loss: 0.1097 - acc: 0.9569\n","Epoch 30/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9549WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 313ms/step - loss: 0.1322 - acc: 0.9549\n","Epoch 31/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9625WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 332ms/step - loss: 0.1019 - acc: 0.9629\n","Epoch 32/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9607WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 317ms/step - loss: 0.1161 - acc: 0.9611\n","Epoch 33/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9622WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 316ms/step - loss: 0.1050 - acc: 0.9629\n","Epoch 34/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9654WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 314ms/step - loss: 0.1059 - acc: 0.9660\n","Epoch 35/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9607WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 335ms/step - loss: 0.1077 - acc: 0.9609\n","Epoch 36/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9633WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 313ms/step - loss: 0.1035 - acc: 0.9634\n","Epoch 37/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9709WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 313ms/step - loss: 0.0836 - acc: 0.9709\n","Epoch 38/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9633WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 331ms/step - loss: 0.0986 - acc: 0.9637\n","Epoch 39/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9709WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 317ms/step - loss: 0.0834 - acc: 0.9709\n","Epoch 40/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9657WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 315ms/step - loss: 0.0961 - acc: 0.9654\n","Epoch 41/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9668WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 319ms/step - loss: 0.0873 - acc: 0.9669\n","Epoch 42/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9718WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 328ms/step - loss: 0.0829 - acc: 0.9711\n","Epoch 43/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9715WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 319ms/step - loss: 0.0776 - acc: 0.9717\n","Epoch 44/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9686WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 315ms/step - loss: 0.0918 - acc: 0.9680\n","Epoch 45/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9692WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 335ms/step - loss: 0.0881 - acc: 0.9691\n","Epoch 46/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9709WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 317ms/step - loss: 0.0900 - acc: 0.9706\n","Epoch 47/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9697WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 318ms/step - loss: 0.0889 - acc: 0.9697\n","Epoch 48/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9767WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 323ms/step - loss: 0.0700 - acc: 0.9769\n","Epoch 49/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9686WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 18s 332ms/step - loss: 0.0906 - acc: 0.9680\n","Epoch 50/50\n","54/55 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9689WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n","55/55 [==============================] - 17s 314ms/step - loss: 0.0912 - acc: 0.9674\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"LWB5jRk2gQHP","colab_type":"code","colab":{},"outputId":"0aba6e03-b2b7-4ba3-f0c5-021392484379"},"source":["#final_loss, final_accuracy = model.evaluate(x_val, y_val)\n","#print('Final Loss: {}, Final Accuracy: {}'.format(final_loss, final_accuracy))\n","\n","final_loss, final_accuracy = model.evaluate(x_test, y_test)\n","print('Final Loss: {}, Final Accuracy: {}'.format(final_loss, final_accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["420/420 [==============================] - 2s 4ms/sample - loss: 0.2394 - acc: 0.9357\n","Final Loss: 0.23943055779479133, Final Accuracy: 0.9357143044471741\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"qo_EU-D4gQHT","colab_type":"code","colab":{},"outputId":"2830e781-ae96-4aaa-8472-8ddea73e39ff"},"source":["import matplotlib.pyplot as plt\n","plt.plot(History.history['acc'])\n","plt.plot(History.history['val_acc'])\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epochs')\n","plt.legend(['train', 'test'])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'val_acc'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-e62aabfd93bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'val_acc'"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"trusted":true,"id":"hkr4nq6GgQHW","colab_type":"code","colab":{}},"source":["# getting predictions on val set.\n","pred=model.predict(x_test)\n","pred_digits=np.argmax(pred,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"D539_fACgQHb","colab_type":"code","colab":{}},"source":["\n","# now storing some properly as well as misclassified indexes'.\n","i=0\n","prop_class=[]\n","mis_class=[]\n","\n","for i in range(len(y_test)):\n","    if(np.argmax(y_test[i])==pred_digits[i]):\n","        prop_class.append(i)\n","    if(len(prop_class)==8):\n","        break\n","\n","i=0\n","for i in range(len(y_test)):\n","    if(not np.argmax(y_test[i])==pred_digits[i]):\n","        mis_class.append(i)\n","    if(len(mis_class)==8):\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"z2C7AbgygQHg","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.filterwarnings('always')\n","warnings.filterwarnings('ignore')\n","\n","count=0\n","fig,ax=plt.subplots(4,2)\n","fig.set_size_inches(15,15)\n","for i in range (4):\n","    for j in range (2):\n","        ax[i,j].imshow(x_test[mis_class[count]])\n","        ax[i,j].set_title(\"Predicted Flower :\"+str(le.inverse_transform([pred_digits[mis_class[count]]]))+\"\\n\"+\"Actual Flower : \"+str(le.inverse_transform([np.argmax(y_test[mis_class[count]])])))\n","        plt.tight_layout()\n","        count+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"iEruLOWbgQHj","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}